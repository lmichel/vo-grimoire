[
  {
    "_index": "mails",
    "_type": "message",
    "_id": "uG6QnHEBIN9-GU1ceCb4",
    "_score": 1.0,
    "_source": {
      "from": "David Berry <dsb@ast.man.ac.uk>",
      "body": {
        "plain": "Brian,\n\n> > If you have a simple 1D array of numbers, your starting point is surely\n> > to say the pixel value is dependent on the pixel index. The measured\n> > discrete pixel values are the fundamental thing we are describing here,\n> > not the underlying continuous physical function of flux on frequency. The\n> > Quantity meta-data should allow you to move from what you *have* (i.e. the\n> > dependancy of pixel value on pixel index) to what you *want* (e.g. the\n> > dependancy of flux on frequency).\n>\n> David, all,\n>\n> But pixel index *can* be a quantity. It most certainly is not simply\n> an index of a dimension. It does have units (\"unitless\") and data type\n> (\"integer\") and error (\"no error, exact value\"). The pixel index can be\n> a function of any set of integer numbers (admittedly its usually\n> positive) but there is no set understanding of where that pixel index\n> number starts. It may be 0 or 1, (or possibly something else if you have\n> weird numbering) whereas the index of that dimension should start always\n> at some common conventional value (I prefer \"0\"; purely speaking here as\n> a C programmer). For example, the underlying index could maps to the\n> pixel index as follows:\n>\n> index  0   1    2    3    4     5     ...   N\n> pixel   1   2    3    4    19   20    ...   M\n>\n> where I can choose to make the mapping as I like between the integers.\n> In the case above, I have \"reordered\" the placement of the 19th and 20th\n> row of pixels to their underlying location in the data array at position 4,5.\n\nI'd go along with you here, but I would translate what you're saying into\nwhat (for me) would be a simpler concept that \"the values stored within\na pixel array can themselves be pixel indices into another pixel array\".\n[A detail - just because something is dimensionless does not mean it\ndoesn't have units - \"angle\" is dimensionless but has units (rad.s,\ndegrees, etc). One could possible argue that a value which represents a\ncount (such as pixel index) should have a \"unit\" of the thing which is\nbeing counted. Thus a pixel index value of 10 could be thought of as \"10\npixels\" i.e. the units would be \"pixel\".]\n\n\n> > One point to note is that whilst \"what we have\" is always the same (i.e.\n> > we have the dependancy of pixel value on pixel index), there may be\n> > several options for \"what we want\". For instance, for a simple CCD image\n> > of the sky, we may want the dependancy of (RA,DEC) on pixel index, or\n> > alternatively we may want the dependancy of focal plane position on pixel\n> > index. Presumably, in your model you would express this by saying that\n> > flux is a function of sky position, which is a function of focal plane\n> > position, which is a function of pixel index? How do you decide on the\n> > dependancy order?\n>\n> \tDependancy is seen by nesting the order of the functions (quantities). Using\n> \tyour example:\n>\n> \tF ( S )\n>\n> \tis the flux quantity \"F\", \"S\" is the sky position quantity where S is a function\n> \tof RA, DEC quantities, ie.\n>\n> \tS => S(RA,DEC)\n>\n> \tand RA, DEC are functions of respective pixel indices I, J, e.g.\n>\n> \tRA(I,J)\n>\n> \tand\n>\n> \tDEC(I,J)\n>\n> \tand I, J are mappings from underylying \"matrix' indexes i, j ,eg.\n>\n> \tI(i,j)\n>\n> \tJ(i,j)\n>\n> \twhere i, j by convention are whole number ordered sets that identify the location\n> \tof the data.\n\nWhat about focal plane coordinates (e.g. (x,y) in millimetres from the\ntelescope boresight)? The flux could equally be thought of as a function\nof focal plane position. And there could potentially be other coordinate\nsystems - for instance, if you take a cut-out from a big image you could\nthink of flux as a function of pixel index in the cut-out image, or as\na function of pixel index in the original entire image. My question is how\ndoes you scheme cope with what FITS-WCS calls alternate axis descriptions?\nA general solution should be able to cope with an arbitrary number of\nalternate axis descriptions.\n\nUsing the sort of [WCS] idea I've mentioned in the past, this sort of\nQuantity would have a WCS component which could be represented as a tree:\n\n                       PIXEL\n                       / | \\\n       ----------------  |  ------------------\n       |                 |                   |\n      SKY           FOCAL_PLANE        PARENT_PIXEL\n\nEach word represents a \"Frame\" object (i.e. a description of a coordinate\nsystem, e.g. using Arnold Rots STC schema), and each the dashed line\nrepresents a \"Mapping\" object (i.e. a recipe which describes how to\ntransform positions between the two Frames connected by the line).\nThis sort of structure captures all the information regarding axis\ndependancies, and is easy to extend indefinitely.\n\nOne more question about your scheme... when you have quantities which are\nfunctions of other quantities, do the argument quantities contain actual\nnumerical values? Back to the CCD example, we have a quantity representing\nthe flux values - this quantity presumably contains the actual flux values.\nIn your model this quantity is a function of another quantity representing\nsky position. Does this sub-quantity also contain arrays of actual\nnumerical RA and DEC values?\n\n\n----------------------------------------------------------------------\nDr David S. Berry    (dsb@ast.man.ac.uk)\n\nSTARLINK project                        Centre for Astrophysics\n(http://www.starlink.ac.uk/)            University of Central Lancashire\nRutherford Appleton Laboratory          PRESTON\nDIDCOT                                  United Kingdom\nUnited Kingdom                          PR1 2HE\nOX11 0QX\n"
      },
      "in-reply-to": "<200311040658.42224.thomas@mail630.gsfc.nasa.gov>",
      "timestamp": 1067950972.0,
      "id": "<Pine.OSF.4.53.0311041212020.16537@axp0.ast.man.ac.uk>",
      "thread-topic": "none",
      "thread-index": "none",
      "references": "<Pine.LNX.4.44.0310301350570.373-100000@poplar.ncsa.uiuc.edu>\n <3FA65885.8070204@gsfc.nasa.gov> <Pine.OSF.4.53.0311040940550.17596@axp0.ast.man.ac.uk>\n <200311040658.42224.thomas@mail630.gsfc.nasa.gov>"
    }
  },
  {
    "_index": "mails",
    "_type": "message",
    "_id": "uW6QnHEBIN9-GU1ceSYF",
    "_score": 1.0,
    "_source": {
      "from": "Steve Lowe <slowe@head-cfa.harvard.edu>",
      "body": {
        "plain": "Hi All,\n\nI went back an reviewed Alberto Micol's original posting on this thread, \nand I must say that I agree with it wholeheartedly with many of his \npoints. I would like to add some thoughts about use cases based on my \nobservation of the NVO correspondence during the past year.\n\nMany of the design proposals I've read skip some important steps in \nhurrying to a final design specification. These proposals (my own \nincluded, I'm afraid) lay out data structures and operations that the \nauthor(s) believe will be useful for data retrieval and analysis. The \ndifficulty is that there are an endless list of features that *could* be \nuseful, and this leads to endless disputes over which ones to include. \nWhat is needed is to set priorities on the capabilities on that long list.\n\nTo do this, I agree with others that have posted that we should pay \nattention to use cases. I wish to add that I believe the use cases need \nto be described more completely, or perhaps to say it a different way, \nthe requirements implied by those use cases need to be set out in much \nmore detail. This may have been said before, but if so, it is worth \nrepeating.\n\nI would like to see use cases that step through a particular calculation \nto identify exactly what capabilities the author thinks are needed. This \nwould also be an opportunity for the author to express an opinion on how \nthe processing responsibilities would be divided up among the data \nprovider, the data model implementation, and the data user.\n\nFor example, consider determining the luminosity of an object from a CCD \nimage. For a *particular* object, image and instrument, the use case \nscenario would provide answers to many detailed questions. What are the \nsteps, what do you do to manipulate the data? (The steps I describe here \nmay not be right; I'm just trying to illustrate the level of detail that \nI'm talking about.) First off, one might select a region within which to \nsum the pixel values. How would you specify the boundary of the region, \nhow much freedom or precision do you need (not in general, but for this \nparticular case)? Is it on the sky or on the detector? Are pixels that \nstraddle the boundary in or out of the region, or perhaps for those \npixels you need a value indicating the fraction of overlap with the \nregion. Or you may need more exact information than this. What position \nerror information does your analysis require?\n\nThen you need to add up the fluxes. Is it to be assumed that, as \ndelivered by the data provider, the pixel data values are linearly \nrelated to flux, so one can add the values directly? What information do \nyou need related to saturation? And so on.\n\nI think detailed scenarios like these are needed for data analyses that \npeople actually do, and they need to be written down.\n\nObviously, preparing complete use case scenarios will be a lot of work. \nHowever, a collection of them might make it possible to\n- identify and prioritize specific functional capabilities\n- decide on a target capability set from the prioritized list---this \nclarifies goals for DM design\n- verify that proposed DM elements meet that target---that is, the \ntarget set would be a basis to check design proposals against\nA careful analysis like this would move us more quickly toward a real \ndesign.\n\nSteve\n\n-- \nSteve Lowe\nSmithsonian Astrophysical Observatory\nHarvard-Smithsonian Center for Astrophysics\nslowe@cfa.harvard.edu\n1-617-496-1661\n\n\nAlberto Micol wrote:\n >\n > Dear All,\n >\n > At this point my feeling is that we are going nowhere.\n > All these discussions about quantities  are too phylosophical for me.\n >\n > We need to focus on what we want to achieve, provided that it is clear\n > to everybody what the goal is. I might be wrong, but I do not think that\n > the goal is well identified within the group. (After all, this is why I\n > called\n > for user cases).\n > I do not believe that defining a generic thing call quantity will \nbring us\n > anything immediately useful. It is too generic.\n >\n > For example, sorry Brian, I do not understand the requirements in\n > http://nvo.gsfc.nasa.gov/cgi-bin/view_requirements.pl\n > Most of them in my opinion are not requirements, but definitions.\n >\n > Requirements should describe what is to be achieved, and not\n > which class is associated with what, or who inherits from who.\n > And too generic requirements (quantity will be used to facilitate\n > search, etc)\n > bring nowhere either.\n >\n > In all cases, I do not find useful to start from the Quantity level.\n >\n > Let's concentrate on the top level things we need to solve for the VO,\n > eg, how to describe coverage (bandpasses, regions, time intervals, \ndepths)\n > of existing data products, how to describe images, spectra, light curves,\n > exposure maps, visibilities, etc, how to package products, etc.\n >\n > Those should be the starting points, because that is what we have to\n > describe\n > in the 99% of the cases.\n >\n > In the process of developing a data model to cope with these (already\n > complex)\n > aspects, we will find the needs to define other things like Quantity,\n > Phenomena,\n > or anything else that WILL RESULT USEFUL in the process. Not the \nother way\n > around!\n >\n > I thought that it was decided that we start with Observational Data \nModel,\n > and not with Quantities. That is certainly a much more pragmatic point\n > of view,\n > am I wrong ?\n >\n > Alberto\n >\n\n"
      },
      "in-reply-to": "none",
      "timestamp": 1067959626.0,
      "id": "<3FA7C54A.2050607@head-cfa.harvard.edu>",
      "thread-topic": "none",
      "thread-index": "none",
      "references": "<200310281629.44369.brian.thomas@gsfc.nasa.gov> <200310281346.04065.patrick.dowler@nrc-cnrc.gc.ca> <200310281803.34055.thomas@mail630.gsfc.nasa.gov> <3F9F9BD9.3070300@eso.org>"
    }
  },
  {
    "_index": "mails",
    "_type": "message",
    "_id": "um6QnHEBIN9-GU1ceSYS",
    "_score": 1.0,
    "_source": {
      "from": "Brian Thomas <brian.thomas@gsfc.nasa.gov>",
      "body": {
        "plain": "\n\tDavid,\n\n\tOverall, some semantics aside, I think we are largely in agreement\n\t(with one slight difference noted at the bottom of this letter).\n\tNow, reponses  to your responses. \n\nOn Tuesday 04 November 2003 08:02 am, David Berry wrote:\n> Brian,\n> [snip]\n> > a C programmer). For example, the underlying index could maps to the\n> > pixel index as follows:\n> >\n> > index  0   1    2    3    4     5     ...   N\n> > pixel   1   2    3    4    19   20    ...   M\n> >\n> > where I can choose to make the mapping as I like between the integers.\n> > In the case above, I have \"reordered\" the placement of the 19th and 20th\n> > row of pixels to their underlying location in the data array at position\n> > 4,5.\n>\n> I'd go along with you here, but I would translate what you're saying into\n> what (for me) would be a simpler concept that \"the values stored within\n> a pixel array can themselves be pixel indices into another pixel array\".\n\n\tI can agree with your quoted statement as well. Thats, in essence, \n\tat the root of the idea that quantities may serve as axes (indices) on\n\tother quantities.\n\n> [A detail - just because something is dimensionless does not mean it\n> doesn't have units - \"angle\" is dimensionless but has units (rad.s,\n> degrees, etc). One could possible argue that a value which represents a\n> count (such as pixel index) should have a \"unit\" of the thing which is\n> being counted. Thus a pixel index value of 10 could be thought of as \"10\n> pixels\" i.e. the units would be \"pixel\".]\n\n\tAgree about dimensionality. Not sure if \"pixel\" is a unit, but the VO \n\t*could* define it as such. I'd rather see \"pixel\" as a UCD/concept that is a \n\tclass that inherits from \"quantity\", but I'm not a stickler on this point.\n\n> [snip]\n> > > How do you decide on the dependancy order?\n> >\n> > \tDependancy is seen by nesting the order of the functions (quantities).\n> > Using your example:\n> >\n> > \tF ( S )\n> >\n> > \tis the flux quantity \"F\", \"S\" is the sky position quantity where S is a\n> > function of RA, DEC quantities, ie.\n> >\n> > \tS => S(RA,DEC)\n> > [snip]\n\n>\n> What about focal plane coordinates (e.g. (x,y) in millimetres from the\n> telescope boresight)? The flux could equally be thought of as a function\n> of focal plane position. And there could potentially be other coordinate\n> systems - for instance, if you take a cut-out from a big image you could\n> think of flux as a function of pixel index in the cut-out image, or as\n> a function of pixel index in the original entire image. My question is how\n> does you scheme cope with what FITS-WCS calls alternate axis descriptions?\n\n\tAh, good question. I think this is handled by having a mapping between\n\tany one set of quantities (like RA, DEC) and another (like B,L).  Thus, even\n\tthough the \"S\" the sky coordinate is formally defined as a function of \n\tthe quantity set {RA,DEC}, the mapping between that set, and the {B,L}\n\tset allows you to easily specify S as a function of B,L, eg.\n\n\tS(RA1,DEC1) == S(B1,L1)\n\n\t(or focal plane to RA,DEC, etc)\n\n> A general solution should be able to cope with an arbitrary number of\n> alternate axis descriptions.\n\n\tTotally agree. I believe this solution allows that. The set {RA,DEC} should\n\thave a pointer/hook to all mappings that it obeys. The user should be able\n\tto extend this set from the \"canonical\" one to include their local mappings.\n\tThus, while the mapping {RA,DEC} <=> {B,L} is canonical, and always \n\tavailable, {x,y} <=> {RA,DEC} (mapping between instrument focal plane and\n\tsky ra,dec) may be an add-on mapping for a particular quantity (say \"flux\",\n\tthat you measured from a camera).\n\n>\n> Using the sort of [WCS] idea I've mentioned in the past, this sort of\n> Quantity would have a WCS component which could be represented as a tree:\n>\n>                        PIXEL\n>                        / | \\\n>        ----------------  |  ------------------\n>\n>       SKY           FOCAL_PLANE        PARENT_PIXEL\n>\n> Each word represents a \"Frame\" object (i.e. a description of a coordinate\n> system, e.g. using Arnold Rots STC schema), and each the dashed line\n> represents a \"Mapping\" object (i.e. a recipe which describes how to\n> transform positions between the two Frames connected by the line).\n\n\tYes, I believe we agree, with minor differences in  the semantic difference \n\tof \"Frame\" vs. \"set of quantities\" is our difference, and that I would\n\tprefer that some \"primary\" frame (say pixels in {x,y}) exists within the \n\tquantity being interrogated. I desire this primary frame because it has\n\timpact on the dimensionality of the units. Consider that a F(lambda)\n\tarray has values which are in units of erg cm^-2 s^-1 wavelength^-1. If\n\tI choose to store F(i) (where \"i\" is a dimensionless pixel index) then the \n\tunits are different, e.g. erg cm^-2 s^-1 pixel^-1. Thus, \"set\" holds information\n\tof \"frame\" but further may include information about unit dimensionality,\n\tand thus, a \"primary\" set is needed.\n\t\n\t(hope that was an intelligible explanation)\n\n> One more question about your scheme... when you have quantities which are\n> functions of other quantities, do the argument quantities contain actual\n> numerical values? Back to the CCD example, we have a quantity representing\n> the flux values - this quantity presumably contains the actual flux values.\n> In your model this quantity is a function of another quantity representing\n> sky position. Does this sub-quantity also contain arrays of actual\n> numerical RA and DEC values?\n\n\tYes, the sub-quantity it may be actual arrays of numerical values OR these \n\tvalues may be generated from an underlying algorithm. \n\n\tRegards,\n\n\t=b.t.\n\n>\n>\n> ----------------------------------------------------------------------\n> Dr David S. Berry    (dsb@ast.man.ac.uk)\n>\n> STARLINK project                        Centre for Astrophysics\n> (http://www.starlink.ac.uk/)            University of Central Lancashire\n> Rutherford Appleton Laboratory          PRESTON\n> DIDCOT                                  United Kingdom\n> United Kingdom                          PR1 2HE\n> OX11 0QX\n\n-- \n\n  * Dr. Brian Thomas \n\n  * Code 630.1 \n  * Goddard Space Flight Center NASA\n\n  *   fax: (301) 286-1775\n  * phone: (301) 286-6128\n\n"
      },
      "in-reply-to": "<Pine.OSF.4.53.0311041212020.16537@axp0.ast.man.ac.uk>",
      "timestamp": 1067958048.0,
      "id": "<200311041000.48805.brian.thomas@gsfc.nasa.gov>",
      "thread-topic": "none",
      "thread-index": "none",
      "references": "<Pine.LNX.4.44.0310301350570.373-100000@poplar.ncsa.uiuc.edu> <200311040658.42224.thomas@mail630.gsfc.nasa.gov> <Pine.OSF.4.53.0311041212020.16537@axp0.ast.man.ac.uk>"
    }
  },
  {
    "_index": "mails",
    "_type": "message",
    "_id": "u26QnHEBIN9-GU1ceSYe",
    "_score": 1.0,
    "_source": {
      "from": "David Berry <dsb@ast.man.ac.uk>",
      "body": {
        "plain": "Brian,\n\n> > Using the sort of [WCS] idea I've mentioned in the past, this sort of\n> > Quantity would have a WCS component which could be represented as a tree:\n> >\n> >                        PIXEL\n> >                        / | \\\n> >        ----------------  |  ------------------\n> >        |                 |                   |\n> >       SKY           FOCAL_PLANE        PARENT_PIXEL\n> >\n> > Each word represents a \"Frame\" object (i.e. a description of a coordinate\n> > system, e.g. using Arnold Rots STC schema), and each dashed line\n> > represents a \"Mapping\" object (i.e. a recipe which describes how to\n> > transform positions between the two Frames connected by the line).\n>\n> Yes, I believe we agree, with minor differences in  the semantic\n> difference of \"Frame\" vs. \"set of quantities\" is our difference, and\n> that I would prefer that some \"primary\" frame (say pixels in {x,y})\n> exists within the quantity being interrogated. I desire this primary\n> frame because it has impact on the dimensionality of the units. Consider\n> that a F(lambda) array has values which are in units of erg cm^-2 s^-1\n> wavelength^-1. If I choose to store F(i) (where \"i\" is a dimensionless\n> pixel index) then the units are different, e.g. erg cm^-2 s^-1 pixel^-1.\n> Thus, \"set\" holds information of \"frame\" but further may include\n> information about unit dimensionality, and thus, a \"primary\" set is\n> needed.\n\nThe idea of a \"Frame\" is that it provides all information needed to\ninterpret a set of numerical values describing a position in some\ncorresponding coordinate system - this includes units. Not sure I'm\nunderstanding you fully here. If you have an array of flux values and a\nmethod to return the flux at a given position, are you saying that you\nwant the returned value converted to different units depending on how you\nspecify the position (i.e. erg.cm^-2.s^-1.m^-1 if you specify the position\nas a wavelength, erg.cm^-2.s^-1.Hz^-1 if you specify the position as a\nfrequency, etc)? Whilst the change in returned units may be nice, it is\nnot a logical necessity of specifying the position in different a system -\nyou *could* legitimately return the value in erg.cm^-2.s^-1.m^-1 even if\nyou specified the position in Hz.\n\nNone-the-less, it would obviously be a useful thing to be able to do. To\nwrite a such a method may require extra meta-data in the [UNITS] component.\nThe [UNITS] component would describe pixel *value* in the same way\nthat [WCS] describes pixel *position* (i.e. each component would be a\n\"FrameSet\" - a collection of coordinate Frames connected together by\nMappings):\n\n\n     [UNITS]                               [WCS]\n    =========                             =======\n\n   PIXEL_VALUE                          PIXEL_INDEX\n        |                                    |\n        |                                    |\n        v                                    v\n      FLUX[ NormFrame ]              SPECTRAL_POSITION\n\nThe \"SPECTRAL_POSITION\" Frame would describe frequency, wavelength,\nvelocity, etc, The \"FLUX\" Frame would describe the flux units, and\nwould encapsulate another Frame (labelled \"NormFrame\") which describes\nthe coordinate system in which the flux values are normalised (wavelength,\nfrequency, pixel, etc). A method to find the flux, F, at a given position,\nX, normalised to the system in which the position X is specified, would\nthen work as follows:\n\n   - Use [WCS] to find the index, P, of the pixel which includes\n     position X.\n   - Use [WCS] to find the width, W1, of pixel P in the frame in which\n     position X is given.\n   - Use [WCS] to find the width, W2, of pixel P in the \"NormFrame\"\n     frame (there are known, canonical Mappings between any pair of\n     frames describing spectral positions).\n   - Use [UNITS] to convert the value of pixel P into the FLUX frame\n   - Convert this flux value from the FLUX frame (i.e. normalised in the\n     system specified by NormFrame) to the required frame, by multplying\n     it by W2/W1.\n\n> > One more question about your scheme... when you have quantities which are\n> > functions of other quantities, do the argument quantities contain actual\n> > numerical values? Back to the CCD example, we have a quantity representing\n> > the flux values - this quantity presumably contains the actual flux values.\n> > In your model this quantity is a function of another quantity representing\n> > sky position. Does this sub-quantity also contain arrays of actual\n> > numerical RA and DEC values?\n>\n> Yes, the sub-quantity it may be actual arrays of numerical values OR these\n> values may be generated from an underlying algorithm.\n\nSo there would be no need to store values for the RA and DEC of every\npixel in an image (just checking)??\n\nDavid\n\n----------------------------------------------------------------------\nDr David S. Berry    (dsb@ast.man.ac.uk)\n\nSTARLINK project                        Centre for Astrophysics\n(http://www.starlink.ac.uk/)            University of Central Lancashire\nRutherford Appleton Laboratory          PRESTON\nDIDCOT                                  United Kingdom\nUnited Kingdom                          PR1 2HE\nOX11 0QX\n\n"
      },
      "in-reply-to": "<200311041000.48805.brian.thomas@gsfc.nasa.gov>",
      "timestamp": 1067964412.0,
      "id": "<Pine.OSF.4.53.0311041527180.20840@axp0.ast.man.ac.uk>",
      "thread-topic": "none",
      "thread-index": "none",
      "references": "<Pine.LNX.4.44.0310301350570.373-100000@poplar.ncsa.uiuc.edu>\n <200311040658.42224.thomas@mail630.gsfc.nasa.gov>\n <Pine.OSF.4.53.0311041212020.16537@axp0.ast.man.ac.uk>\n <200311041000.48805.brian.thomas@gsfc.nasa.gov>"
    }
  },
  {
    "_index": "mails",
    "_type": "message",
    "_id": "vG6QnHEBIN9-GU1ceSYo",
    "_score": 1.0,
    "_source": {
      "from": "Brian Thomas <brian.thomas@gsfc.nasa.gov>",
      "body": {
        "plain": "\n\tDavid,\n\nOn Tuesday 04 November 2003 11:46 am, you wrote:\n> > Yes, the sub-quantity it may be actual arrays of numerical values OR\n> > these values may be generated from an underlying algorithm.\n>\n> So there would be no need to store values for the RA and DEC of every\n> pixel in an image (just checking)??\n\n\tNot exactly. I'll try to explain. \n\t\n\tAs we have it, the values in the quantity are generated. Now, if a quantity is \n\tspecifying the values on an axis, then yes, the axis values are generated from \n\tan algorithm. Using your example above (choosing a 1-D linear \"stripe\" of pixels \n\tacross the sky), we have the relationship between \"pixel no\" and internal\n\tindex:\n\nindex         0   1   2   3    4   5 .. N\npixel no  10 11 12 13 14 15 .. M\n\n\twhere the \"pixel no\" values aren't stored, but may be generated by the linear\n\talgorithm : \"1*x + 10\" which is recorded in the \"pixel no\" quantity which has\n\tdependence on \"index\". The Ra, Dec values would be derived by a mapping \n\tbetween the pixel no and Ra, Dec \"quantity sets\" which is a different algorithm, so \n\tthat {pixel no} <=> {Ra,Dec}. The 2 algorithms, one for index to pixel no and\n\tthe other, a mapping between frames, are required. The only \"stored\" data\n\twould be the size of the 1-D array. Thus, its possible to get\n\n\t{Ra1, Dec1 } <=> {PixelNo1} <=> {i}\n\n\twhere the \"bridge\" between the Ra,Dec and PixelNo sets is from a mapping/frame\n\ttransform and the second one is from mapping algorithm converting the internal\n\tindex to pixel no values.\n\n\tHope thats clear explanation. Having a choice between storing the mapping in \n\tan algorithm that creates the values of a quantity vs. having the algorithm in a \n\tfull-on transform object may seem a bit untidy. I guess I see a need for 2 different\n\tmethods because the difference is that you dont need a full-on coordinate transform \n\tto go from internal index to value because its always a one-to-one conversion \n\t(one index always converts to a single value) whereas the frame conversion may \n\tchange from one *set* of values to another set (of one or more values) as in \n\t{RA,DEC} <=> {PixelNo}. \n\n\tI guess I could  be persuded that its \"formally\" best to have only one way to \n\tconvert numbers, and create a \"simple\" frame conversion class for the index\n\tto value mappings.  I would just hope the implementation of the simple frame \n\ttransform is \"light\" so that there isnt any extraneous meta-data to bulk up the\n\tquantity being passed round/stored.\n\n\tRegards,\n\n\t-b.t.\n\n-- \n\n  * Dr. Brian Thomas \n\n  * Code 630.1 \n  * Goddard Space Flight Center NASA\n\n  *   fax: (301) 286-1775\n  * phone: (301) 286-6128\n\n"
      },
      "in-reply-to": "<Pine.OSF.4.53.0311041527180.20840@axp0.ast.man.ac.uk>",
      "timestamp": 1067966503.0,
      "id": "<200311041221.43076.brian.thomas@gsfc.nasa.gov>",
      "thread-topic": "none",
      "thread-index": "none",
      "references": "<Pine.LNX.4.44.0310301350570.373-100000@poplar.ncsa.uiuc.edu> <200311041000.48805.brian.thomas@gsfc.nasa.gov> <Pine.OSF.4.53.0311041527180.20840@axp0.ast.man.ac.uk>"
    }
  },
  {
    "_index": "mails",
    "_type": "message",
    "_id": "vW6QnHEBIN9-GU1ceSYx",
    "_score": 1.0,
    "_source": {
      "from": "Brian Thomas <brian.thomas@gsfc.nasa.gov>",
      "body": {
        "plain": "On Tuesday 04 November 2003 11:46 am, David Berry wrote:\n> > Yes, I believe we agree, with minor differences in  the semantic\n> > difference of \"Frame\" vs. \"set of quantities\" is our difference, and\n> > that I would prefer that some \"primary\" frame (say pixels in {x,y})\n> > exists within the quantity being interrogated. I desire this primary\n> > frame because it has impact on the dimensionality of the units. Consider\n> > that a F(lambda) array has values which are in units of erg cm^-2 s^-1\n> > wavelength^-1. If I choose to store F(i) (where \"i\" is a dimensionless\n> > pixel index) then the units are different, e.g. erg cm^-2 s^-1 pixel^-1.\n> > Thus, \"set\" holds information of \"frame\" but further may include\n> > information about unit dimensionality, and thus, a \"primary\" set is\n> > needed.\n>\n> The idea of a \"Frame\" is that it provides all information needed to\n> interpret a set of numerical values describing a position in some\n> corresponding coordinate system - this includes units. Not sure I'm\n> understanding you fully here. \n> [snip]\n\n\tAh, then there is an additional difference. I understood \"frame\" to\n\tbe a set of values (not necessarily for a position) that have associated\n\tunits. So my definition is more expansive. Which raises my question:\n\tWhy limit to just positional transforms?\n\n> If you have an array of flux values and a\n> method to return the flux at a given position, are you saying that you\n> want the returned value converted to different units depending on how you\n> specify the position (i.e. erg.cm^-2.s^-1.m^-1 if you specify the position\n> as a wavelength, erg.cm^-2.s^-1.Hz^-1 if you specify the position as a\n> frequency, etc)? Whilst the change in returned units may be nice, it is\n> not a logical necessity of specifying the position in different a system -\n> you *could* legitimately return the value in erg.cm^-2.s^-1.m^-1 even if\n> you specified the position in Hz.\n\n\tYes, you are right. The user should be allowed an option to get their\n\tvalues in either way (e.g. in the example above w/ or w/o the \"Hz\").\n\n>\n> None-the-less, it would obviously be a useful thing to be able to do. To\n> write a such a method may require extra meta-data in the [UNITS] component.\n> The [UNITS] component would describe pixel *value* in the same way\n> that [WCS] describes pixel *position* (i.e. each component would be a\n> \"FrameSet\" - a collection of coordinate Frames connected together by\n> Mappings):\n>\n>\n>      [UNITS]                               [WCS]\n>     =========                             =======\n>\n>    PIXEL_VALUE                          PIXEL_INDEX\n>         |                                    |\n>         |                                    |\n>         v                                    v\n>       FLUX[ NormFrame ]              SPECTRAL_POSITION\n>\n> The \"SPECTRAL_POSITION\" Frame would describe frequency, wavelength,\n> velocity, etc, The \"FLUX\" Frame would describe the flux units, and\n> would encapsulate another Frame (labelled \"NormFrame\") which describes\n> the coordinate system in which the flux values are normalised (wavelength,\n> frequency, pixel, etc). A method to find the flux, F, at a given position,\n> X, normalised to the system in which the position X is specified, would\n> then work as follows:\n>\n>    - Use [WCS] to find the index, P, of the pixel which includes\n>      position X.\n>    - Use [WCS] to find the width, W1, of pixel P in the frame in which\n>      position X is given.\n>    - Use [WCS] to find the width, W2, of pixel P in the \"NormFrame\"\n>      frame (there are known, canonical Mappings between any pair of\n>      frames describing spectral positions).\n>    - Use [UNITS] to convert the value of pixel P into the FLUX frame\n>    - Convert this flux value from the FLUX frame (i.e. normalised in the\n>      system specified by NormFrame) to the required frame, by multplying\n>      it by W2/W1.\n\n\tI *think* I follow this..and agree, with the sole exception/nitpick that I dont \n\tsee why we must limit having framesets defined in terms of positional systems. \n\t(for example, in your above example things revolve around passing pixel\n\tcoordinates. I would like to think we could do the same abound non-positional\n\tthings like \"lambda\" as well, consider a \"reverse\" example where I can use\n\tthe \"lamdba\" value to find the \"pixel\" on an image that contains an echelle spectra.\n\tOther mapping examples may have no positions at all (such as flux to magnitude)).\n\t\n\tSo to reinterate: I agree WCS forms a critical set of transforms/mappings we must\n\tinclude...I just want to insure that other kinds of transformations can be done\n\twith the same system.\n\n \tRegards,\n\n\t=b.t.\n\n\n-- \n\n  * Dr. Brian Thomas \n\n  * Code 630.1 \n  * Goddard Space Flight Center NASA\n\n  *   fax: (301) 286-1775\n  * phone: (301) 286-6128\n\n"
      },
      "in-reply-to": "<Pine.OSF.4.53.0311041527180.20840@axp0.ast.man.ac.uk>",
      "timestamp": 1067967255.0,
      "id": "<200311041234.15129.brian.thomas@gsfc.nasa.gov>",
      "thread-topic": "none",
      "thread-index": "none",
      "references": "<Pine.LNX.4.44.0310301350570.373-100000@poplar.ncsa.uiuc.edu> <200311041000.48805.brian.thomas@gsfc.nasa.gov> <Pine.OSF.4.53.0311041527180.20840@axp0.ast.man.ac.uk>"
    }
  },
  {
    "_index": "mails",
    "_type": "message",
    "_id": "vm6QnHEBIN9-GU1ceSY6",
    "_score": 1.0,
    "_source": {
      "from": "David Berry <dsb@ast.man.ac.uk>",
      "body": {
        "plain": "Brian\n\n> > The idea of a \"Frame\" is that it provides all information needed to\n> > interpret a set of numerical values describing a position in some\n> > corresponding coordinate system - this includes units. Not sure I'm\n> > understanding you fully here.\n> > [snip]\n>\n> \tAh, then there is an additional difference. I understood \"frame\" to\n> \tbe a set of values (not necessarily for a position) that have associated\n> \tunits. So my definition is more expansive. Which raises my question:\n> \tWhy limit to just positional transforms?\n\nSorry - my poor choice of words. I'm using the word \"position\" is in its\nmost general sense, not just referring to \"spatial position\". If you\nhave a plot of \"number of sheep\" on the Y axis against \"farm size\" on the\nX axis, then a resulting (X,Y) pair would be a \"position\" in my sense of\nthe word (i.e. a position within the coordinate space covered by these two\naxes). So in this sense, values for wavelength, frequency, flux, time,\netc, are all \"positions\" within some corresponding Frame.\n\nBut note, a Frame does not itself encapsulate a set of numerical axis\nvalues, it just provides a description of the axis. It is the job of a\nhigher level structure (like a Quantity) to associate a Frame with a set\nof numerical axis values.\n\n\n> > None-the-less, it would obviously be a useful thing to be able to do. To\n> > write a such a method may require extra meta-data in the [UNITS] component.\n> > The [UNITS] component would describe pixel *value* in the same way\n> > that [WCS] describes pixel *position* (i.e. each component would be a\n> > \"FrameSet\" - a collection of coordinate Frames connected together by\n> > Mappings):\n> >\n> >\n> >      [UNITS]                               [WCS]\n> >     =========                             =======\n> >\n> >    PIXEL_VALUE                          PIXEL_INDEX\n> >         |                                    |\n> >         |                                    |\n> >         v                                    v\n> >       FLUX[ NormFrame ]              SPECTRAL_POSITION\n> >\n> > The \"SPECTRAL_POSITION\" Frame would describe frequency, wavelength,\n> > velocity, etc, The \"FLUX\" Frame would describe the flux units, and\n> > would encapsulate another Frame (labelled \"NormFrame\") which describes\n> > the coordinate system in which the flux values are normalised (wavelength,\n> > frequency, pixel, etc). A method to find the flux, F, at a given position,\n> > X, normalised to the system in which the position X is specified, would\n> > then work as follows:\n> >\n> >    - Use [WCS] to find the index, P, of the pixel which includes\n> >      position X.\n> >    - Use [WCS] to find the width, W1, of pixel P in the frame in which\n> >      position X is given.\n> >    - Use [WCS] to find the width, W2, of pixel P in the \"NormFrame\"\n> >      frame (there are known, canonical Mappings between any pair of\n> >      frames describing spectral positions).\n> >    - Use [UNITS] to convert the value of pixel P into the FLUX frame\n> >    - Convert this flux value from the FLUX frame (i.e. normalised in the\n> >      system specified by NormFrame) to the required frame, by multplying\n> >      it by W2/W1.\n>\n> I *think* I follow this..and agree, with the sole exception/nitpick that\n> I dont see why we must limit having framesets defined in terms of\n> positional systems. (for example, in your above example things revolve\n> around passing pixel coordinates. I would like to think we could do the\n> same abound non-positional things like \"lambda\" as well, consider a\n> \"reverse\" example where I can use the \"lamdba\" value to find the \"pixel\"\n> on an image that contains an echelle spectra. Other mapping examples may\n> have no positions at all (such as flux to magnitude)).\n\nAgain, apologies for my overloaded use of the word \"position\". Frames can\nindeed pass things like lambda around, and your reverse example fits well\ninto the model.\n\n\n> So to reinterate: I agree WCS forms a critical set of transforms/mappings\n> we must include...I just want to insure that other kinds of\n> transformations can be done with the same system.\n\nAbsolutely agree.\n\nDavid\n\n----------------------------------------------------------------------\nDr David S. Berry    (dsb@ast.man.ac.uk)\n\nSTARLINK project                        Centre for Astrophysics\n(http://www.starlink.ac.uk/)            University of Central Lancashire\nRutherford Appleton Laboratory          PRESTON\nDIDCOT                                  United Kingdom\nUnited Kingdom                          PR1 2HE\nOX11 0QX\n\n"
      },
      "in-reply-to": "<200311041234.15129.brian.thomas@gsfc.nasa.gov>",
      "timestamp": 1067969392.0,
      "id": "<Pine.OSF.4.53.0311041755090.23635@axp0.ast.man.ac.uk>",
      "thread-topic": "none",
      "thread-index": "none",
      "references": "<Pine.LNX.4.44.0310301350570.373-100000@poplar.ncsa.uiuc.edu>\n <200311041000.48805.brian.thomas@gsfc.nasa.gov>\n <Pine.OSF.4.53.0311041527180.20840@axp0.ast.man.ac.uk>\n <200311041234.15129.brian.thomas@gsfc.nasa.gov>"
    }
  },
  {
    "_index": "mails",
    "_type": "message",
    "_id": "v26QnHEBIN9-GU1ceSZD",
    "_score": 1.0,
    "_source": {
      "from": "Ed Shaya <Edward.J.Shaya.1@gsfc.nasa.gov>",
      "body": {
        "plain": "Dave,\n\n  I am not completely familiar with what is in this Frame object, but I \nhave been assuming\nit is information on the reference frame.  In which case I agree.  That \nis not a Quantity.\nThe reference frame information is metadata.  WCS, however, does provide the\nkeywords necessary to describe the axis.  Those keywords are the axis \nQuantities, in\nalgorithmic or abstract form.  The reference frame info is metadata \nwithin that Quantity.\n\nEd\n\n\nDavid Berry wrote:\n\n>But note, a Frame does not itself encapsulate a set of numerical axis\n>values, it just provides a description of the axis. It is the job of a\n>higher level structure (like a Quantity) to associate a Frame with a set\n>of numerical axis values.\n>\n>  \n>\n"
      },
      "in-reply-to": "<Pine.OSF.4.53.0311041755090.23635@axp0.ast.man.ac.uk>",
      "timestamp": 1068040282.0,
      "id": "<3FA9005A.8030002@gsfc.nasa.gov>",
      "thread-topic": "none",
      "thread-index": "none",
      "references": "<Pine.LNX.4.44.0310301350570.373-100000@poplar.ncsa.uiuc.edu> <200311041000.48805.brian.thomas@gsfc.nasa.gov> <Pine.OSF.4.53.0311041527180.20840@axp0.ast.man.ac.uk> <200311041234.15129.brian.thomas@gsfc.nasa.gov> <Pine.OSF.4.53.0311041755090.23635@axp0.ast.man.ac.uk>"
    }
  },
  {
    "_index": "mails",
    "_type": "message",
    "_id": "wG6QnHEBIN9-GU1ceSZK",
    "_score": 1.0,
    "_source": {
      "from": "David Berry <dsb@ast.man.ac.uk>",
      "body": {
        "plain": "Ed,\n\n> I am not completely familiar with what is in this Frame object, but I\n> have been assuming it is information on the reference frame.  In which\n> case I agree.  That is not a Quantity. The reference frame information\n> is metadata.  WCS, however, does provide the keywords necessary to\n> describe the axis.  Those keywords are the axis Quantities, in\n> algorithmic or abstract form.  The reference frame info is metadata\n> within that Quantity.\n\nI think we agree (except for differences in nomenclature) - WCS would\ncontain one or more Frames, each Frame describing a coordinate system in\nwhich the position of a data value within the associated data structure\ncan be expressed. The WCS would also contain the Mappings (equivalent to\n\"algorithms\"?) to enable a position in one Frame to be transformed into\nany of the other Frames.\n\nDavid\n\n----------------------------------------------------------------------\nDr David S. Berry    (dsb@ast.man.ac.uk)\n\nSTARLINK project                        Centre for Astrophysics\n(http://www.starlink.ac.uk/)            University of Central Lancashire\nRutherford Appleton Laboratory          PRESTON\nDIDCOT                                  United Kingdom\nUnited Kingdom                          PR1 2HE\nOX11 0QX\n\n"
      },
      "in-reply-to": "<3FA9005A.8030002@gsfc.nasa.gov>",
      "timestamp": 1068041463.0,
      "id": "<Pine.OSF.4.53.0311051405480.2372@axp0.ast.man.ac.uk>",
      "thread-topic": "none",
      "thread-index": "none",
      "references": "<Pine.LNX.4.44.0310301350570.373-100000@poplar.ncsa.uiuc.edu>\n <200311041000.48805.brian.thomas@gsfc.nasa.gov>\n <Pine.OSF.4.53.0311041527180.20840@axp0.ast.man.ac.uk>\n <200311041234.15129.brian.thomas@gsfc.nasa.gov>\n <Pine.OSF.4.53.0311041755090.23635@axp0.ast.man.ac.uk> <3FA9005A.8030002@gsfc.nasa.gov>"
    }
  },
  {
    "_index": "mails",
    "_type": "message",
    "_id": "wW6QnHEBIN9-GU1ceSZT",
    "_score": 1.0,
    "_source": {
      "from": "Ed Shaya <Edward.J.Shaya.1@gsfc.nasa.gov>",
      "body": {
        "plain": "Here is what we are talking about in a rough, possible serialized form.\nI am just guessing that this algorithm would like input in the form of\ntuples of the index values (which normally would be generated by some other\nalgorithm, but here I just type them in).   Frame is now a collection\nof the various quantities (epoch, centerRA, centerDE, pixelsPerArcsec, etc)\nneeded for the transformation.  Sorry, no UML for you Pierre, maybe later.\n\nFluxQ\n    Argument\n       positionQ\n    ValueList\n       list of flux values\n\npositionQ\n    Argument\n          Index(NAxis1)\n    Argument\n          Index(NAxis2)\n    DataFormat\n          tuple\n               int\n               int\n    ValueList\n          0,0 0,1 0,2 ...\n          1,0 1,1 1,2 ...\n             ...\n    Mapping\n         Algorithm\n             algorithmID\n                 http://ivoa.net/algorithms/WCS/position/iiRaDec.c\n         Input\n             frame1\n     Mapping\n         Algorithm\n              algorithmID\n                 http://ivoa.net/algorithms/WCS/position/iiGalactic.c\n         Input\n              alternateFrame2\n\n\nEd\n\n\n\nDavid Berry wrote:\n\n>Ed,\n>\n>  \n>\n>>I am not completely familiar with what is in this Frame object, but I\n>>have been assuming it is information on the reference frame.  In which\n>>case I agree.  That is not a Quantity. The reference frame information\n>>is metadata.  WCS, however, does provide the keywords necessary to\n>>describe the axis.  Those keywords are the axis Quantities, in\n>>algorithmic or abstract form.  The reference frame info is metadata\n>>within that Quantity.\n>>    \n>>\n>\n>I think we agree (except for differences in nomenclature) - WCS would\n>contain one or more Frames, each Frame describing a coordinate system in\n>which the position of a data value within the associated data structure\n>can be expressed. The WCS would also contain the Mappings (equivalent to\n>\"algorithms\"?) to enable a position in one Frame to be transformed into\n>any of the other Frames.\n>\n>David\n>\n>----------------------------------------------------------------------\n>Dr David S. Berry    (dsb@ast.man.ac.uk)\n>\n>STARLINK project                        Centre for Astrophysics\n>(http://www.starlink.ac.uk/)            University of Central Lancashire\n>Rutherford Appleton Laboratory          PRESTON\n>DIDCOT                                  United Kingdom\n>United Kingdom                          PR1 2HE\n>OX11 0QX\n>\n>\n>  \n>\n"
      },
      "in-reply-to": "<Pine.OSF.4.53.0311051405480.2372@axp0.ast.man.ac.uk>",
      "timestamp": 1068044481.0,
      "id": "<3FA910C1.2080402@gsfc.nasa.gov>",
      "thread-topic": "none",
      "thread-index": "none",
      "references": "<Pine.LNX.4.44.0310301350570.373-100000@poplar.ncsa.uiuc.edu> <200311041000.48805.brian.thomas@gsfc.nasa.gov> <Pine.OSF.4.53.0311041527180.20840@axp0.ast.man.ac.uk> <200311041234.15129.brian.thomas@gsfc.nasa.gov> <Pine.OSF.4.53.0311041755090.23635@axp0.ast.man.ac.uk> <3FA9005A.8030002@gsfc.nasa.gov> <Pine.OSF.4.53.0311051405480.2372@axp0.ast.man.ac.uk>"
    }
  }
]